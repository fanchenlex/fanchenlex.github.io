<!doctype html>
<html lang="en"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>VLA-Adapter | arxiv 2025.9.11 | Paper Reading - Zhuo&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Zhuo&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Zhuo&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="VLA-ADAPTER: AN EFFECTIVE PARADIGM FOR TINY-SCALE VISION-LANGUAGE-ACTION MODEL 这篇文章通过设计了一个bridge Attenion block以及广泛的实验尝试验证了小模型也能够有很好的性能。"><meta property="og:type" content="blog"><meta property="og:title" content="VLA-Adapter | arxiv 2025.9.11 | Paper Reading"><meta property="og:url" content="https://fanchenlex.github.io/reandings/VLA-ADAPTER/"><meta property="og:site_name" content="Zhuo&#039;s Blog"><meta property="og:description" content="VLA-ADAPTER: AN EFFECTIVE PARADIGM FOR TINY-SCALE VISION-LANGUAGE-ACTION MODEL 这篇文章通过设计了一个bridge Attenion block以及广泛的实验尝试验证了小模型也能够有很好的性能。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://fanchenlex.github.io/img/VLA-Adapterfront.png"><meta property="article:published_time" content="2025-11-02T05:35:50.000Z"><meta property="article:modified_time" content="2025-11-02T05:39:18.973Z"><meta property="article:author" content="Wenzhuo Li"><meta property="article:tag" content="paper reading"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://fanchenlex.github.io/img/VLA-Adapterfront.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://fanchenlex.github.io/reandings/VLA-ADAPTER/"},"headline":"VLA-Adapter | arxiv 2025.9.11 | Paper Reading","image":["https://fanchenlex.github.io/img/VLA-Adapterfront.png"],"datePublished":"2025-11-02T05:35:50.000Z","dateModified":"2025-11-02T05:39:18.973Z","author":{"@type":"Person","name":"Wenzhuo Li"},"publisher":{"@type":"Organization","name":"Zhuo's Blog","logo":{"@type":"ImageObject","url":"https://fanchenlex.github.io/img/logo.png"}},"description":"VLA-ADAPTER: AN EFFECTIVE PARADIGM FOR TINY-SCALE VISION-LANGUAGE-ACTION MODEL 这篇文章通过设计了一个bridge Attenion block以及广泛的实验尝试验证了小模型也能够有很好的性能。"}</script><link rel="canonical" href="https://fanchenlex.github.io/reandings/VLA-ADAPTER/"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Zhuo's Blog" type="application/atom+xml">
</head><body class="is-3-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Zhuo&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/categories/blogs">Blogs</a><a class="navbar-item" href="/publications">Publications</a><a class="navbar-item" href="/categories/projects">Projects</a><a class="navbar-item" href="/categories/courses">Courses</a><a class="navbar-item" href="/gallery">Gallery</a><a class="navbar-item" href="/categories/readings">Readings</a><a class="navbar-item" href="/categories/diary">Diary</a><a class="navbar-item" href="/archives">archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/fanchenlex"><i class="fab fa-github"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/VLA-Adapterfront.png" alt="VLA-Adapter | arxiv 2025.9.11 | Paper Reading"></span></div><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile">VLA-Adapter | arxiv 2025.9.11 | Paper Reading</h1><div class="article-meta is-size-7 is-uppercase level is-mobile mt-2"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-11-02T05:35:50.000Z" title="2025/11/2 13:35:50">2025-11-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-11-02T05:39:18.973Z" title="2025/11/2 13:39:18">2025-11-02</time></span><span class="level-item"><a class="link-muted" href="/categories/readings/">readings</a></span><span class="level-item">13 minutes read (About 1991 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><p>VLA-ADAPTER: AN EFFECTIVE PARADIGM FOR TINY-SCALE VISION-LANGUAGE-ACTION MODEL</p>
<h3 id="这篇文章通过设计了一个bridge-Attenion-block以及广泛的实验尝试验证了小模型也能够有很好的性能。"><a href="#这篇文章通过设计了一个bridge-Attenion-block以及广泛的实验尝试验证了小模型也能够有很好的性能。" class="headerlink" title="这篇文章通过设计了一个bridge Attenion block以及广泛的实验尝试验证了小模型也能够有很好的性能。"></a>这篇文章通过设计了一个bridge Attenion block以及广泛的实验尝试验证了小模型也能够有很好的性能。</h3><span id="more"></span>
<table style="width:100%; border-collapse:collapse;">
  <thead style="border-bottom:1px solid #ccc;">
    <tr>
      <th style="padding:8px; text-align:center;">工作类型(首次/改进)</th>
      <th style="padding:8px; text-align:center;">技术路线</th>
      <th style="padding:8px; text-align:center;">创新点</th>
      <th style="padding:8px; text-align:center;">日期</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="padding:8px; text-align:center;">首次</td>
      <td style="padding:8px; text-align:center;">adapter</td>
      <td style="padding:8px; text-align:center;">bridge Attention</td>
      <td style="padding:8px; text-align:center;">2025-10-07</td>
    </tr>
  </tbody>
</table>

<h2 id="1-What？"><a href="#1-What？" class="headerlink" title="1.What？"></a>1.What？</h2><p>为了解决如何有效衔接视觉-语言表征与动作空间这一问题，提出VLA-Adapter这一创新范式，旨在降低VLA模型对大规模VLM和大量预训练的依赖。<br>首先系统分析了不同VL条件的有效性，并揭示了哪些条件对衔接感知与动作空间至关重要的关键发现。基于这些洞见，我们设计出带有桥接注意力机制的轻量化策略模块，可自主将最优条件注入动作空间。VLA-Adapter将充足的多模态信息传递至所提策略网络以生成动作，有效弥合了从视觉语言到动作的模态鸿沟。<br>该方法仅需0.5B参数的主干网络即可实现高性能，且无需任何机器人数据预训练。在仿真与真实机器人基准测试上的大量实验表明，VLA-Adapter不仅达到最先进性能水平，还实现了目前报道中最快的推理速度。得益于提出的先进桥接范式，VLA-Adapter仅需在单张消费级GPU上训练8小时即可构建强大VLA模型，大幅降低了VLA模型的部署门槛。</p>
<h2 id="2-Why？"><a href="#2-Why？" class="headerlink" title="2.Why？"></a>2.Why？</h2><p>（i）SFT扩展所需的大规模人工示教轨迹数据稀缺且成本高昂；<br>（ii）对存在分布偏移任务的泛化能力有限。<br>面对高维控制环境时，VLA模型仍存在多重瓶颈：依赖大规模视觉语言模型、微调速度缓慢、GPU显存消耗高以及推理效率（吞吐量）低下<br>大规模具身数据集进行预训练将VLM与专用策略网络相结合，使系统能够以端到端方式解析或生成多样化任务的动作序列。此外，双系统VLA架构近期受到关注，这类方法通常引入中间潜在标记连接VLM与策略网络，通过异步机制增强双系统协同，从而缓解动作生成过程中的延迟问题。因此，如何高效衔接视觉语言感知空间与动作空间已成为VLA模型设计的核心挑战。</p>
<h2 id="3-How？"><a href="#3-How？" class="headerlink" title="3.How？"></a>3.How？</h2><p><img src="/img/VLtoAparadigms.png" alt="Existing representative bridge paradigms from VL to A"><br>该视觉语言模型遵循PrismaticVLMs架构，包含M个网络层。在时间步t时，输入VLM的数据包含 ${\mathcal{X}_t^v,\mathcal{X}_t^g,\mathcal{L}_t,\mathcal{A}\mathcal{Q}_t}:$第三视角图像$\mathcal{X}_t^v$、夹爪图像$\mathcal{X}_t^g$、指令文本Lt以及动作查询$\mathcal{A}\mathcal{Q}_t$。输入$\mathcal{X}_t^v$和$\mathcal{X}_t^g$后，分别通过DINOv2和SigLIP提取视觉嵌入表示(每一个都是过两个编码器与openvla-oft输入方式一样)，Lt则进行分词处理。输出为指定层的原始潜在表示$\mathcal{C}_t^{\mathcal{R}}$和动作查询潜在表示 $\mathcal{C}^{\mathcal{A}\mathcal{Q}}_t$，二者共同作为策略网络的输入条件。输出是：xxxxxx<br>在第t个时间步，策略网络的输入包括：${\mathcal{C}_t^{\mathcal{R}},\mathcal{C}_t^{\mathcal{AQ}},\mathcal{A}_t^{\tau&#x3D;0},\mathcal{P}_t}$。τ表示策略网络的层级，满足τ ∈ Z+且0 ≤ τ ≤ M−1。At0是H步零初始化动作序列，经过层归一化（LN）和多层感知机（MLP）处理得到Ae t0 &#x3D; aet0, aet0+1, …, ae0 t+H−1。Pt为本体感知状态，通过两层MLP映射获得本体嵌入表征σ0(Pt)。网络输出为H步动作块AM−1 t。每层结构由桥式注意力模块和前馈网络（FFN）构成，桥式注意力架构如图5所示。<br><img src="/img/VLAAdapterframework.png" alt="The proposed VLA framework"><br><img src="/img/VLA-AdapterBridgeAttention.png" alt="The Policy with Bridge Attention"><br>桥注意力机制。提出的桥注意力旨在通过条件$\mathcal{C}_t^{\mathcal{R}}$和$\mathcal{C}_t^{\mathcal{AQ}}$最大限度地引导动作生成。每个桥注意力包含两个交叉注意力层和一个自注意力层。首个交叉注意力层中，$\mathcal{C}_t^{\mathcal{R}}$经MLP网络σ1处理得到K1、V1，动作潜在表示Ae_tτ作为Q1执行注意力计算，获得CA1(Ae_tτ, σ1($\mathcal{C}_t^{\mathcal{R}}$))。次个交叉注意力层需将$\mathcal{C}_t^{\mathcal{AQ}}$与σ0(Pt)拼接后经MLP网络σ2处理得到K2、V2，以Ae_tτ作为Q2获取CA2(Ae_tτ, σ2($\mathcal{C}_t^{\mathcal{AQ}}$, σ0(Pt)))。自注意力层中以Ae_tτ同时作为Q、K、V，执行SA(Ae_tτ, Ae_tτ)运算。为选择性地将特定$\mathcal{C}_t^{\mathcal{R}}$注入策略的动作空间，我们引入学习参数比率g来调节CA1(Ae_tτ, σ1($\mathcal{C}_t^{\mathcal{R}}$))的影响程度。g初始化为0值，并采用tanh激活函数使tanh(g)∈[-1,1]，以防止极端值破坏分布稳定性（Zhang等，2023）。最终将三个注意力输出拼接得到Ab_tτ</p>
<h2 id="4-Takeaways"><a href="#4-Takeaways" class="headerlink" title="4.Takeaways:"></a>4.Takeaways:</h2><p>关键发现1：在$\mathcal{C}_t^{\mathcal{R}}$方面，中层潜表征性能优于深层潜表征。深层$\mathcal{C}_t^{\mathcal{R}}$偏向语义信息而弱于动作生成。中层$\mathcal{C}_t^{\mathcal{R}}$能有效融合图像与文本信息，保留更丰富的多模态细节，有利于动作生成。<br>关键发现2：对于$\mathcal{C}^{\mathcal{A}\mathcal{Q}}_t$，深层潜表征表现优于其他层级。由于ActionQuery是从头开始训练的，深层$\mathcal{C}^{\mathcal{A}\mathcal{Q}}_t$聚合了更丰富的多模态细节，比浅层更能有效促进动作生成。<br>关键发现3：多层特征组合性能更优。我们观察到使用全层级特征通常优于单层特征，不仅提升性能，还能节省设计过程中的最佳层级选择时间。这种设计更具普适性。<br>条件判定。VLA-Adapter是否完全依赖$\mathcal{C}_t^{\mathcal{AQ}}$作为条件？答案是否定的。虽然全层$\mathcal{C}^{\mathcal{A}\mathcal{Q}}_t$优于$\mathcal{C}_t^{\mathcal{R}}$，但中间层$\mathcal{C}_t^{\mathcal{R}}$在某些复杂任务中表现更佳。对比结果如表1所示。因此，我们旨在通过利用$\mathcal{C}_t^{\mathcal{R}}$的特定知识来提升性能。<br>结论一：当视觉语言模型未经过机器人预训练时，VLA-Adapter的改进效果显著。<br>结论二：即使主干网络参数冻结，VLA-Adapter仍能保持强劲性能。<br>VLA-Adapter无需机器人预训练即可实现视觉语言模型的高效微调，其性能超越采用微型主干网络的基线方法<br>局限性&amp;未来工作：<br>1.经过大量具身数据预训练且模型规模微小，其在现实系统中的泛化能力有待提升<br>2.策略网络生成动作的质量取决于视觉语言模型提供的条件及其利用方式-&gt;深入探索这些条件以改进其表征能力并确保高效利用<br>3.VLA-Adapter的基础训练流程仍相对简单-&gt;可探索强化学习等复杂训练流程</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>VLA-Adapter | arxiv 2025.9.11 | Paper Reading</p><p><a href="https://fanchenlex.github.io/reandings/VLA-ADAPTER/">https://fanchenlex.github.io/reandings/VLA-ADAPTER/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Wenzhuo Li</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2025-11-02</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2025-11-02</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/paper-reading/">paper reading</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=68c2a0486bd80d4bd2a04d20&amp;product=sop" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/Alipay.JPG" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechatpay.png" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/reandings/RDP/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">RDP | RSS 2025 | Paper Reading</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/reandings/RoboTwin2.0/"><span class="level-item">RoboTwin 2.0 | arxiv 2025.8.27(preprint) | Paper Reading</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Wenzhuo Li"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Wenzhuo Li</p><p class="is-size-6 is-block">Embodied AI</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>PALM Lab, Nanjing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded is-flex is-align-items-center" href="https://github.com/fanchenlex" target="_blank" rel="me noopener"><span class="icon is-small mr-1"><i class="fab fa-github"></i></span><span>Follow</span></a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="WeChat" href="https://fanchenlex.github.io/img/WeChat.jpg" style="display:flex;alignItems:center;padding:0.5rem;"><img src="/img/WeChat_icon.png" alt="WeChat" style="width:2.5rem;height:2.5rem;objectFit:contain;borderRadius:50%;backgroundColor:rgba(255, 255, 255, 0.1);padding:0.5rem;"></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="QQ" href="https://fanchenlex.github.io/img/qq.jpg" style="display:flex;alignItems:center;padding:0.5rem;"><img src="/img/QQ_icon.png" alt="QQ" style="width:2.5rem;height:2.5rem;objectFit:contain;borderRadius:50%;backgroundColor:rgba(255, 255, 255, 0.1);padding:0.5rem;"></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Email" href="https://wx.mail.qq.com/home/index?sid=zUwweozORVYudWN4AAZJUQAA#/compose?mailid=ZD0006_UBzNrmCMMkcubmgAwu8omf7" style="display:flex;alignItems:center;padding:0.5rem;"><img src="/img/QQ_email.png" alt="Email" style="width:2.5rem;height:2.5rem;objectFit:contain;borderRadius:50%;backgroundColor:rgba(255, 255, 255, 0.1);padding:0.5rem;"></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="DailyLog" href="https://fanchenlex.github.io/pdf/DailyLog.pdf" style="display:flex;alignItems:center;padding:0.5rem;"><img src="/img/DailyLog.png" alt="DailyLog" style="width:2.5rem;height:2.5rem;objectFit:contain;borderRadius:50%;backgroundColor:rgba(255, 255, 255, 0.1);padding:0.5rem;"></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="/atom.xml" style="display:flex;alignItems:center;padding:0.5rem;"><img src="/img/RSS.gif" alt="RSS" style="width:2.5rem;height:2.5rem;objectFit:contain;borderRadius:50%;backgroundColor:rgba(255, 255, 255, 0.1);padding:0.5rem;"></a></div></div><style>
				.widget[data-type=&quot;profile&quot;] .level-item.button img {
					transition: all 0.3s ease;
					opacity: 0.8;
				}
				
				.widget[data-type=&quot;profile&quot;] .level-item.button:hover img {
					opacity: 1;
					transform: scale(1.1);
					background-color: rgba(255, 255, 255, 0.2);
				}
				
				.widget[data-type=&quot;profile&quot;] .level-item.button:hover i {
					transform: scale(1.1);
				}
			</style></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label"><i class="fas fa-bullhorn" style="margin-right: 6px;"></i>ANNOUNCEMENT</h3><div class="announcement"><ul class="menu-list"><li><i class="fas fa-megaphone" style="color: #3498db; margin-right: 6px;"></i><a class="announcement-link" href="/diary/southeast_letter/">[2025-07-02] Unboxing the Southeast University Graduate Admission Letter.</a></li><li><i class="fas fa-megaphone" style="color: #3498db; margin-right: 6px;"></i><a class="announcement-link" href="/diary/japan_Kansai/">[2025-07-01] Completed graduation trip with my mom —— Kansai, Japan.</a></li><li><i class="fas fa-megaphone" style="color: #3498db; margin-right: 6px;"></i><a class="announcement-link" href="/diary/xidian_memories/">[2025-06-20] Graduating from Xidian University.</a></li></ul></div><div style="margin-top: 10px; text-align: center;"><a href="/announcement/">View All Announcements &gt;&gt;</a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Awards/"><span class="level-start"><span class="level-item">Awards</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/blogs/"><span class="level-start"><span class="level-item">blogs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/collaboration/"><span class="level-start"><span class="level-item">collaboration</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/diary/"><span class="level-start"><span class="level-item">diary</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/projects/"><span class="level-start"><span class="level-item">projects</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/readings/"><span class="level-start"><span class="level-item">readings</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/11/"><span class="level-start"><span class="level-item">November 2025</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/10/"><span class="level-start"><span class="level-item">October 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/09/"><span class="level-start"><span class="level-item">September 2025</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/07/"><span class="level-start"><span class="level-item">July 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">June 2025</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><div class="recent-posts"><div class="media" style="display:flex;align-items:flex-start;margin-bottom:15px;"><div class="media-left" style="margin-right:10px;"><p class="image is-64x64"><img src="/img/RDPfront.png" alt="thumbnail" style="object-fit:cover;"></p></div><div class="media-content"><p style="color: #888; font-size: 0.85em; margin:0;">2025-11-02</p><p style="margin:0;"><a class="recent-title-link" href="/reandings/RDP/">RDP | RSS 2025 | Paper Reading</a></p><p style="margin:0;"><a class="recent-category-link" href="/categories/readings/">readings</a></p></div></div><div class="media" style="display:flex;align-items:flex-start;margin-bottom:15px;"><div class="media-left" style="margin-right:10px;"><p class="image is-64x64"><img src="/img/VLA-Adapterfront.png" alt="thumbnail" style="object-fit:cover;"></p></div><div class="media-content"><p style="color: #888; font-size: 0.85em; margin:0;">2025-11-02</p><p style="margin:0;"><a class="recent-title-link" href="/reandings/VLA-ADAPTER/">VLA-Adapter | arxiv 2025.9.11 | Paper Reading</a></p><p style="margin:0;"><a class="recent-category-link" href="/categories/readings/">readings</a></p></div></div><div class="media" style="display:flex;align-items:flex-start;margin-bottom:15px;"><div class="media-left" style="margin-right:10px;"><p class="image is-64x64"><img src="/img/robotwin2front.png" alt="thumbnail" style="object-fit:cover;"></p></div><div class="media-content"><p style="color: #888; font-size: 0.85em; margin:0;">2025-11-02</p><p style="margin:0;"><a class="recent-title-link" href="/reandings/RoboTwin2.0/">RoboTwin 2.0 | arxiv 2025.8.27(preprint) | Paper Reading</a></p><p style="margin:0;"><a class="recent-category-link" href="/categories/readings/">readings</a></p></div></div><div class="media" style="display:flex;align-items:flex-start;margin-bottom:15px;"><div class="media-left" style="margin-right:10px;"><p class="image is-64x64"><img src="/img/robotwin.png" alt="thumbnail" style="object-fit:cover;"></p></div><div class="media-content"><p style="color: #888; font-size: 0.85em; margin:0;">2025-11-02</p><p style="margin:0;"><a class="recent-title-link" href="/reandings/RoboTwin1.0/">RoboTwin1.0 | CVPR 2025 | Paper Reading</a></p><p style="margin:0;"><a class="recent-category-link" href="/categories/readings/">readings</a></p></div></div><div class="media" style="display:flex;align-items:flex-start;margin-bottom:15px;"><div class="media-left" style="margin-right:10px;"><p class="image is-64x64"><img src="/img/DP3.png" alt="thumbnail" style="object-fit:cover;"></p></div><div class="media-content"><p style="color: #888; font-size: 0.85em; margin:0;">2025-10-24</p><p style="margin:0;"><a class="recent-title-link" href="/reandings/DP3/">3D Diffusion Policy | RSS 2024(oral) | Paper Reading</a></p><p style="margin:0;"><a class="recent-category-link" href="/categories/readings/">readings</a></p></div></div></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/addmission-letter/"><span class="tag">addmission letter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graduation/"><span class="tag">graduation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/opening-ceremony/"><span class="tag">opening ceremony</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/paper-reading/"><span class="tag">paper reading</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/travel/"><span class="tag">travel</span><span class="tag">3</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Zhuo&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Wenzhuo Li</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p><div class="footer-donate" style="marginTop:1.5em;"><p class="is-size-7 has-text-centered has-text-weight-bold">如果你喜欢本站内容，可以请我喝杯咖啡 ☕</p><div class="donate-icons" style="display:flex;gap:1rem;marginTop:1em;"><div class="donate-icon-item" style="position:relative;"><a title="alipay"><i class="fab fa-alipay" style="fontSize:1.5rem;cursor:pointer;"></i></a><div class="donate-qrcode" style="position:absolute;bottom:150%;left:50%;transform:translateX(-50%);background:#fff;padding:8px;border:1px solid #ddd;boxShadow:0 2px 6px rgba(0,0,0,0.15);zIndex:100;"><img src="/img/Alipay.JPG" alt="alipay 收款码" style="width:240px;height:auto;display:block;"><div class="has-text-centered is-size-7" style="marginTop:0.5em;">ALIPAY</div></div></div><div class="donate-icon-item" style="position:relative;"><a title="wechat"><i class="fab fa-weixin" style="fontSize:1.5rem;cursor:pointer;"></i></a><div class="donate-qrcode" style="position:absolute;bottom:150%;left:50%;transform:translateX(-50%);background:#fff;padding:8px;border:1px solid #ddd;boxShadow:0 2px 6px rgba(0,0,0,0.15);zIndex:100;"><img src="/img/wechatpay.png" alt="wechat 收款码" style="width:240px;height:auto;display:block;"><div class="has-text-centered is-size-7" style="marginTop:0.5em;">WECHAT</div></div></div></div></div></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/1613486248?spm_id_from=333.1007.0.0" style="padding:0.5rem;width:3rem;height:3rem;display:flex;justifyContent:center;alignItems:center;"><img src="/img/Bilibili.svg" alt="Bilibili" style="maxWidth:100%;maxHeight:100%;objectFit:contain;"></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CSDN" href="https://blog.csdn.net/bjddmzdz?type=blog" style="padding:0.5rem;width:3rem;height:3rem;display:flex;justifyContent:center;alignItems:center;"><img src="/img/csdn.png" alt="CSDN" style="maxWidth:100%;maxHeight:100%;objectFit:contain;"></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Rednote" href="https://www.xiaohongshu.com/user/profile/611202a5000000000101c50e" style="padding:0.5rem;width:3rem;height:3rem;display:flex;justifyContent:center;alignItems:center;"><img src="/img/Rednote.png" alt="Rednote" style="maxWidth:100%;maxHeight:100%;objectFit:contain;"></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Notion" href="https://ruby-uranium-845.notion.site/Research-Paper-Planner-201dc477df6b804ba4bad373196d5f03" style="padding:0.5rem;width:3rem;height:3rem;display:flex;justifyContent:center;alignItems:center;"><img src="/img/Notion.png" alt="Notion" style="maxWidth:100%;maxHeight:100%;objectFit:contain;"></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/universe.js"></script></body></html>